#!/usr/bin/env python3

import os
import re
import json
import time
import hashlib
import subprocess
from pathlib import path

# ----------------------------- config -----------------------------

state_dir = path("/var/lib/check_mk_agent/security_watch")
state_file = state_dir / "state.json"

ssh_warn = int(os.getenv("cmk_ssh_fail_warn", "10"))
ssh_crit = int(os.getenv("cmk_ssh_fail_crit", "20"))

susp_proc_warn = int(os.getenv("cmk_susp_proc_warn", "1"))
susp_proc_crit = int(os.getenv("cmk_susp_proc_crit", "3"))

fstab_path = path("/etc/fstab")
cron_paths = [
    path("/etc/crontab"),
    path("/etc/cron.d"),
    path("/etc/cron.daily"),
    path("/etc/cron.hourly"),
    path("/etc/cron.weekly"),
    path("/etc/cron.monthly"),
    path("/var/spool/cron/crontabs"),
]

ip_re = re.compile(r"\bfrom\s+([0-9a-fA-F\.:]+)\b")
fail_re = re.compile(r"(failed password|invalid user|authentication failure)", re.IGNORECASE)

# suspicious process heuristics:
# - execution from /tmp, /dev/shm, /var/tmp
# - "(deleted)" in args (binary removed after launch)
# - some common typo-squat / weird names (conservative)
susp_path_re = re.compile(r"(^|\s)(/tmp/|/dev/shm/|/var/tmp/)", re.IGNORECASE)
susp_name_re = re.compile(r"\b(kworkerd|kworker\d+|systemd--|dbusd--|sshd:)\b", re.IGNORECASE)
deleted_re = re.compile(r"\(deleted\)", re.IGNORECASE)

# ----------------------------- helpers -----------------------------

def load_state():
    try:
        with state_file.open("r") as f:
            return json.load(f)
    except fileNotFoundError:
        return {}
    except exception:
        return {}

def save_state(st):
    state_dir.mkdir(parents=True, exist_ok=True)
    tmp = state_file.with_suffix(".tmp")
    with tmp.open("w") as f:
        json.dump(st, f, indent=2, sort_keys=True)
    os.replace(tmp, state_file)

def local_line(code, svc, msg, perf=""):
    # checkmk local check format: "<state> <service> <perf> <text>"
    if perf:
        print(f"{code} {svc} {perf} {msg}")
    else:
        print(f"{code} {svc} - {msg}")

def sha256_file(p: path) -> str:
    h = hashlib.sha256()
    with p.open("rb") as f:
        for chunk in iter(lambda: f.read(1024 * 1024), b""):
            h.update(chunk)
    return h.hexdigest()

def sha256_tree(paths):
    # deterministic hash of file list (path + content hash)
    files = []
    for p in paths:
        if not p.exists():
            continue
        if p.is_file():
            files.append(p)
        elif p.is_dir():
            for fp in sorted(p.rglob("*")):
                try:
                    if fp.is_file():
                        files.append(fp)
                except oserror:
                    continue

    h = hashlib.sha256()
    for fp in sorted(set(files), key=lambda x: str(x)):
        try:
            h.update(str(fp).encode())
            h.update(b"\0")
            h.update(sha256_file(fp).encode())
            h.update(b"\n")
        except exception:
            h.update(str(fp).encode() + b"\0<unreadable>\n")
    return h.hexdigest(), len(files)

def check_integrity(st, key, svc, compute_fn):
    if "integrity" not in st:
        st["integrity"] = {}

    baseline = st["integrity"].get(key)
    current = compute_fn()

    if baseline is None:
        st["integrity"][key] = current
        local_line(1, svc, "baseline created (first run). verify, then re-run.")
        return

    if baseline != current:
        local_line(2, svc, "changed since baseline. investigate; update baseline if legit.")
    else:
        local_line(0, svc, "ok")

# ----------------------------- ssh check -----------------------------

def run_journalctl_after_cursor(unit: str, cursor: str | None):
    cmd = ["journalctl", "--no-pager", "--output=json", "--show-cursor"]
    if unit:
        cmd += ["-u", unit]
    if cursor:
        cmd += ["--after-cursor", cursor]
    cmd += ["-n", "5000"]  # safety cap

    p = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
    if p.returncode != 0:
        return None, None, f"journalctl error: {p.stderr.strip()[:200]}"

    new_cursor = None
    events = []
    for line in p.stdout.splitlines():
        if line.startswith("-- cursor: "):
            new_cursor = line.replace("-- cursor: ", "").strip()
            continue
        line = line.strip()
        if not line:
            continue
        try:
            obj = json.loads(line)
            msg = obj.get("message", "")
            if msg:
                events.append(msg)
        except json.JSONDecodeError:
            continue
    return events, new_cursor, None

def check_ssh(st):
    if "ssh" not in st:
        st["ssh"] = {}

    cursor = st["ssh"].get("cursor")
    events, new_cursor, err = run_journalctl_after_cursor("ssh", cursor)

    if err is not None:
        local_line(3, "sec_ssh_auth", f"cannot read journal: {err}")
        return

    failures = 0
    ips = {}

    for msg in events:
        if fail_re.search(msg):
            failures += 1
            m = ip_re.search(msg)
            if m:
                ip = m.group(1)
                ips[ip] = ips.get(ip, 0) + 1

    if new_cursor:
        st["ssh"]["cursor"] = new_cursor

    uniq_ips = len(ips)
    top_ip = max(ips.items(), key=lambda kv: kv[1])[0] if ips else "-"

    perf = f"failures={failures};{ssh_warn};{ssh_crit}|uniq_ips={uniq_ips}"
    if failures >= ssh_crit:
        local_line(2, "sec_ssh_auth", f"ssh auth failures: {failures}, uniq_ips={uniq_ips}, top={top_ip}", perf=perf)
    elif failures >= ssh_warn:
        local_line(1, "sec_ssh_auth", f"ssh auth failures: {failures}, uniq_ips={uniq_ips}, top={top_ip}", perf=perf)
    else:
        local_line(0, "sec_ssh_auth", f"ok (failures={failures})", perf=perf)

# ----------------------------- process check -----------------------------

def check_suspicious_processes():
    # list processes once; keep it cheap
    cmd = ["ps", "-eo", "pid=,user=,pcpu=,pmem=,args="]
    p = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
    if p.returncode != 0:
        return None, None, f"ps error: {p.stderr.strip()[:200]}"

    suspicious = []
    for line in p.stdout.splitlines():
        line = line.strip()
        if not line:
            continue

        parts = line.split(None, 4)
        if len(parts) < 5:
            continue

        pid, user, pcpu, pmem, args = parts

        if susp_path_re.search(args) or deleted_re.search(args) or susp_name_re.search(args):
            suspicious.append((pid, user, pcpu, pmem, args[:160]))

    return suspicious, len(suspicious), None

def check_proc():
    susp_list, susp_count, err = check_suspicious_processes()
    if err is not None:
        local_line(3, "sec_proc", f"cannot list processes: {err}")
        return

    examples = "-"
    if susp_count:
        examples = "; ".join([f"{pid}:{user}:{args}" for pid, user, _, _, args in susp_list[:3]])

    perf = f"susp={susp_count};{susp_proc_warn};{susp_proc_crit}"
    if susp_count >= susp_proc_crit:
        local_line(2, "sec_proc", f"suspicious processes: {susp_count} (examples: {examples})", perf=perf)
    elif susp_count >= susp_proc_warn:
        local_line(1, "sec_proc", f"suspicious processes: {susp_count} (examples: {examples})", perf=perf)
    else:
        local_line(0, "sec_proc", f"ok (suspicious={susp_count})", perf=perf)

# ----------------------------- main -----------------------------

def main():
    st = load_state()
    now = int(time.time())

    check_ssh(st)

    def fstab_hash():
        if not fstab_path.exists():
            return "missing"
        return sha256_file(fstab_path)

    check_integrity(st, "fstab_sha256", "sec_fstab", fstab_hash)

    def cron_hash():
        digest, nfiles = sha256_tree(cron_paths)
        return f"{digest}:{nfiles}"

    check_integrity(st, "cron_tree", "sec_cron", cron_hash)

    check_proc()

    st["meta"] = {"last_run": now}
    save_state(st)

if __name__ == "__main__":
    main()
